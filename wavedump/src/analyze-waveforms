#!/usr/bin/env python3
"""
Creates charge histograms from hdf5 files made from `wavedump` or
`acquire-waveforms`.
"""

from __future__ import print_function, division
import h5py
import numpy as np
import pandas as pd
from scipy import signal
import os
import sys
from enum import Enum

canvas = []
hists = []

class Institution(Enum):
    """
    Note: This must be kept in sync with the values in btl_qa.sql.
    """
    caltech = 'Caltech'
    uva = 'UVA'
    rome = 'Rome'

    def __str__(self):
        return self.value

def iqr(x):
    return np.percentile(x,75) - np.percentile(x,25)

def get_threshold_crossing(x, data, threshold=0.4, rising=True):
    """
    Returns the times at which the waveforms in `x` cross `threshold*100`% of
    their minimum value.
    
    WARNING: In cases where a pulse is cut off at the start/end of an event, this function produces a runtime warning.
    """
    data = np.asarray(data)
    argmin = np.argmin(data,axis=-1)
    thresholds = threshold*data[np.arange(data.shape[0]),argmin]
    if rising:
        il = data.shape[1]-np.argmax(((np.arange(data.shape[1]) < argmin[:,np.newaxis]) & (data > thresholds[:,np.newaxis]))[:,::-1],axis=-1)-1
        ir = il + 1
        ir[ir >= data.shape[1]] = data.shape[1]-1
        i = np.arange(data.shape[0])
    else:
        ir = np.argmax(((np.arange(data.shape[1]) > argmin[:,np.newaxis]) & (data > thresholds[:,np.newaxis])),axis=-1)
        il = ir - 1
        il[il < 0] = 0
        i = np.arange(data.shape[0])
    return x[il] + (thresholds-data[i,il])*(x[ir]-x[il])/(data[i,ir]-data[i,il])

def get_rise_time(x, data):
    t10 = get_threshold_crossing(x, data, 0.1)
    t90 = get_threshold_crossing(x, data, 0.9)
    return t90 - t10

def get_fall_time(x, data):
    t10 = get_threshold_crossing(x, data, 0.1, rising=False)
    t90 = get_threshold_crossing(x, data, 0.9, rising=False)
    return t10 - t90

def get_times(x, data, baseline=10):
    """
    Returns the times at which the waveforms in `x` cross 40% of their minimum
    value.
    """
    data = np.asarray(data)
    # Get the first 10 ns of every waveform to calculate the noise level
    noise = iqr(data[:,np.where(x < x[0] + baseline)[0]])
    # Get events with a pulse
    pulses = np.min(data,axis=-1) < -noise*5
    # Select events with pulses. If there are no matches (which might be the
    # case for the triggering channel), then don't apply the selection.
    if np.count_nonzero(pulses):
        data = data[pulses]
    argmin = np.argmin(data,axis=-1)
    threshold = 0.4*data[np.arange(data.shape[0]),argmin]
    return x[data.shape[1]-np.argmax(((np.arange(data.shape[1]) < argmin[:,np.newaxis]) & (data > threshold[:,np.newaxis]))[:,::-1],axis=-1)-1]

def get_window(x, data, left=1, right=10):
    """
    Returns the indices start and stop over which you should integrate the
    waveforms in `x`. The window is found by calculating the median hit time
    for all pulses in `x` and then going back `left` ns and forward `right` ns.
    """
    data = np.asarray(data)
    t = get_times(x,data)
    mean_hit_time = np.median(t)
    a, b = np.searchsorted(x,[mean_hit_time-left,mean_hit_time+right])
    if a < 0:
        a = 0
    if b > len(x) - 1:
        b = len(x) - 1
    return a, b

def get_spe_window(x, start, integration_time):
    """
    Returns the indicies over which the SPE analysis should be integrated.

    `start` and `integration_time` are in nanoseconds, not indexes.
    `start` is relative to the trigger, so `start = 0` is not the first sample,
    but rather the time the trigger fired.
    """
    time_per_index = x[1] - x[0]
    a = int(np.abs(x - start).argmin())
    if a >= len(x) - 1:
        print('SPE integration start time exceeds the acquisition window! Quitting...', file=sys.stderr)
        sys.exit(1)
    b = int(np.round(a + integration_time / time_per_index))
    if b > len(x) - 1:
        print('SPE integration time is too long! Quitting...', file=sys.stderr)
        sys.exit(1)
    return (a,b)

def integrate(x, data, a, b):
    """
    Integrate all waveforms in `data` with times `x`.
    """
    # i = v/r
    # divide by 50 ohms to convert to a charge
    if np.ndim(data) == 2:
        return -np.trapz(data[:,a:b],x=x[a:b])*1000/50.0
    else:
        return -np.trapz(data[a:b],x=x[a:b])*1000/50.0

def get_bins(x, cutoff=None):
    """
    Returns bins for the data `x` using the Freedman Diaconis rule. See
    https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule.
    """
    x = np.asarray(x)

    if cutoff is not None:
        x = x[x > cutoff]
    
    bin_width = 0.5*iqr(x)/(len(x)**(1/3.0))

    if bin_width == 0:
        print('Zero bin width! Quitting...', file=sys.stderr)
        sys.exit(1)
    
    min = np.percentile(x,1)
    max = np.percentile(x,99)
    return np.arange(min,max,bin_width)

def chunks(lst, n):
    """
    Yield successive n-sized chunks from lst.
    """
    for i in range(0, len(lst), n):
        yield (i,i + n)

def convert_data(f, group, channel, start, stop):
    """
    Reads data from opened hdf5 file `f`. Gets the events from `start` to
    `stop` in the dataset `channel`.
    """    
    if 'data_source' in f[group].attrs:
        if f[group].attrs['data_source'] == b'CAEN':
            
            xinc = 1/(f[group].attrs['drs4_frequency'] * 10**6)
            points = f[group].attrs['record_length']
            x = np.linspace(0, xinc * points, int(points)) - xinc * points * (1 - f[group].attrs['post_trigger']/100)
            
            # While `y` is measured in volts, it's only relatively. We could
            # use the DC offset to determine the absolute voltage, but the
            # DC offset isn't well defined. Setting it to about 22000 (DAC
            # units) means approximately no offset is added, but not
            # exactly. This shouldn't matter much because we use a baseline
            # subtraction method anyways.
            y = f[group][channel][start:stop]/2**12
    elif 'yinc' in dict(f[channel].attrs):
        # FIXME: All of the code below assumes that the datasets are in no
        # group. `acquire-waveforms` should be updated first if we want to
        # be able to use this function for oscilloscope data. 
        x = f[channel].attrs['xorg'] + np.linspace(0,f[channel].attrs['xinc']*f[channel].attrs['points'],int(f[channel].attrs['points']))
        # FIXME: I believe the else block in this if/else statement was for
        # a type of hdf5 format that we no longer use.
        if True: # ':WAVeform:FORMat' in dict(f['settings'].attrs) and f['settings'].attrs[':WAVeform:FORMat'] != 'ASC':
            # convert word values -> voltages if the data was saved in a non-ascii format
            y = f[channel][start:stop]*f[channel].attrs['yinc'] + f[channel].attrs['yorg']
        else:
            y = f[channel][start:stop]
    else:
        # In older versions of the code, I stored xorg, xinc, etc.
        # in the main HDF5 group and not on a per channel basis
        x = f.attrs['xorg'] + np.linspace(0,f.attrs['xinc']*f.attrs['points'],int(f.attrs['points']))

        if ':WAVeform:FORMat' in dict(f['settings'].attrs) and f['settings'].attrs[':WAVeform:FORMat'] != 'ASC':
            # convert word values -> voltages if the data was saved in a non-ascii format
            y = f[channel][start:stop]*f.attrs['yinc'] + f.attrs['yorg']
        else:
            y = f[channel][start:stop]
    return x*1e9, y

def low_filter_SPE(x, y):
    """
    Returns `y` through a low pass filter. Edit the cutoff frequency by
    modifying the filter defined below.
    """
    filter_order = 2
    nyquist = (0.5 * (x[1] - x[0]))**(-1)
    cutoff = 5**(-1)
    b, a = signal.butter(filter_order, min(1, cutoff/nyquist), btype='lowpass', output='ba')
    filter_data = signal.lfilter(b, a, y)
    return filter_data

def high_filter_SPE(x, y):
    """
    Returns `y` through a high pass filter. Edit the cutoff frequency by
    modifying the filter defined below.
    """
    filter_order = 2
    nyquist = (0.5 * (x[1] - x[0]))**(-1)
    cutoff = 5**(-1)  # Cut off frequency for the filter measured in inverse nanoseconds
    b, a = signal.butter(filter_order, min(1, cutoff/nyquist), btype='highpass', output='ba')
    filter_data = signal.lfilter(b, a, y)
    return filter_data

def spe_baseline_subtraction(x, y, method=1):
    """ 
    INTEGRATION METHODS
    0: Only per event median subtraction (preformed in every method).
    1 (default): For each event, subtract off the median of all points that lie above `cutoff`.
                 Then, across all events, subtract off the median of all points between `a` and `b`.
    2: Per sample median subtraction. This method is not good because the SPE signal gets diminished.
    3: Delete all trials that have an SPE between `ma` and `mb`. Subtract off the median between `ma` and `mb` on a per event basis.
    4: Same as 3, except no trials are deleted. Trials that have an SPE between `ma` and `mb` get reduced by the total median
       between `ma` and `mb` of events that don't have an SPE in this range.
    """ 
    high_filter_y = high_filter_SPE(x, y)
    
    # Integration Method 0, per event median subtraction:
    y -= np.median(y[:,x <= args.start_time], axis=-1)[:, np.newaxis]
    
    if args.integration_method == 1:  # Default 
        #cutoff = -2*iqr(high_filter_y.flatten())
        #no_SPE_mask = y > cutoff 
        #y -= np.array([np.median(y[i, no_SPE_mask[i]]) for i in range(len(y))])[:, np.newaxis]
        i_mask = np.logical_and(x>=args.start_time, x<args.start_time+args.integration_time)
        y -= np.median(y[:, i_mask])
    elif args.integration_method == 2:
        # `s` for samples
        s = y.T
        s_mask = s > -10*iqr(high_filter_y.flatten())
        good_s = [s[i, s_mask[i]] for i in range(len(s))]
        print(f'average number of good samples: {np.mean([len(sub) for sub in good_s])}')
        sample_medians = np.array([np.median(sub) for sub in good_s])
        y -= sample_medians
    elif args.integration_method == 3:
        ma = -25
        mb = 200
        SPE_trials = np.min(y[:, np.logical_and(x >= ma, x < mb)], axis=-1) < -2 * iqr(high_filter_y[:, np.logical_and(x >= ma, x < mb)].flatten())
        SPE_trials_idx = [i for i in range(len(y)) if SPE_trials[i]]
        y = np.delete(y, SPE_trials_idx, axis=0)
        # Subtract off the median between `ma` and `mb` per event
        y -= np.median(y[:, np.logical_and(x >= ma, x < mb)], axis=-1)[:, np.newaxis]  # per event median subtraction
        if len(y) == 0:
            print('All trials were removed')
    elif args.integration_method == 4:
        ma = -25
        mb = 200
        m_mask = np.logical_and(x>=ma, x<mb)
        no_SPE_trials_mask = np.min(y[:, m_mask], axis=-1) > -2 * iqr(high_filter_y[:, m_mask].flatten())
        y -= np.array([np.median(y[i, m_mask]) if no_SPE_trials_mask[i] else np.median((y[no_SPE_trials_mask, :])[:, m_mask]) for i in range(len(y))])[:, np.newaxis]
    elif args.integration_method != 0:
        print('Not a valid integration method. Defaulting to integration method 0')
    return (y, high_filter_y)

def plot_time_volt(x, y, title, a, b, avg_y=None, pdf=False, filename=None):
    plt.figure()
    plt.subplot(2,1,1)
    plt.plot(x,y[:10].T)
    plt.ylabel("Voltage (V)")
    plt.xlabel("Time (ns)")
    plt.axvline(x[a])
    plt.axvline(x[b])
    plt.subplot(2,1,2)
    if avg_y is not None:
        plt.plot(x,avg_y)
    else:
        plt.plot(x, np.median(y, axis=0))
    plt.xlabel("Time (ns)")
    plt.ylabel("Voltage (V)")
    plt.axvline(x[a])
    plt.axvline(x[b])
    plt.suptitle(title)
    if args.print_pdfs:
        if not filename:
            print('No filename specified; can not print pdf!')
        else:
            root, ext = os.path.splitext(filename)
            plt.savefig(os.path.join(args.print_pdfs, f"{root}_{title}_TimeVolt.pdf"))

def plot_hist(h, pdf=False, filename=None):
    global canvas
    # Naming canvases this way will produce a runtime warning because ROOT
    # will always make a default canvas with name `c1` the first time you
    # fit a histogram. The only way I know how to get rid of it is to
    # overwrite it like this.
    c = ROOT.TCanvas(f'c{len(canvas)+1}')
    canvas.append(c)
    h.Draw()
    c.Update()
    if pdf:
        if not filename:
            print('No filename specified; can not print pdf!')
        else:
            root, ext = os.path.splitext(filename)
            c.Print(os.path.join(pdf, f"{root}_{h.GetName()}.pdf"))

def auto_int(x):
    return int(x, 0)

def ct_mask(ct_ch_chg, ct_511_chg, ct_511_std, thres):
    """
    Returns a mask for ct_ch_chg that is true when the charge is between
    `ct_511_chg - thres*ct_511_std` and `ct_511_chg + thres*ct_511_std`.
    """
    mask_lower = ct_511_chg - thres*ct_511_std < ct_ch_chg
    mask_upper = ct_511_chg + thres*ct_511_std > ct_ch_chg
    return np.logical_and(mask_lower, mask_upper)

if __name__ == '__main__':
    from argparse import ArgumentParser
    import ROOT
    from ROOT import gROOT
    from ROOT import gStyle
    import matplotlib.pyplot as plt
    import psycopg2
    import psycopg2.extensions
    import fit_511_funcs
    import fit_spe_funcs

    parser = ArgumentParser(description='Analyze SPE and 511 charges')
    parser.add_argument('filename',help='input filename (hdf5 format)')
    parser.add_argument('-o','--output', default='delete_me.root', help='output file name')
    parser.add_argument('--plot', default=False, action='store_true', help='plot the waveforms and charge integral')
    parser.add_argument('--chunks', default=1000, type=int, help='number of waveforms to process at a time')
    parser.add_argument('-t', '--integration-time', default=300, type=float, help='SPE integration length in nanoseconds.')
    parser.add_argument('-s', '--start-time',  default=50, type=float, help='start time of the SPE integration in nanoseconds.')
    parser.add_argument('--channel-mask', type=auto_int, default=0xff, help='Channels to analyze data. Default is 0xff. 0x01 would only analyze channel 0.')
    parser.add_argument('--integration-method', type=int, default=1, help='Select a method of integration. Methods described in __main__')
    parser.add_argument("--print-pdfs", default=None, type=str, help="Folder to save pdfs in.")
    parser.add_argument('-u','--upload', default=False, action='store_true', help='upload results to the database')
    parser.add_argument('-i','--institution', default=None, type=Institution, choices=list(Institution), help='name of institution')
    parser.add_argument('--crosstalk', default=None, help='Channel for crosstalk comparison. `0` means select 511 events only from ch0, and compare to all other channels. Default is to compare all possible crosstalk pairs')
    args = parser.parse_args()

    if not args.plot:
        # Disables the canvas from ever popping up
        gROOT.SetBatch()
    else:
        # Shows fit parameters. Only shows them for the first fit however, need to fix this.
        gStyle.SetOptFit(2)

    if args.upload:
        if 'BTL_DB_HOST' not in os.environ:
            print("need to set BTL_DB_HOST environment variable!",file=sys.stderr)
            sys.exit(1)

        if 'BTL_DB_PASS' not in os.environ:
            print("need to set BTL_DB_PASS environment variable!",file=sys.stderr)
            sys.exit(1)

        print("Uploading results to the database...")
        conn = psycopg2.connect(dbname='btl_qa',
                                user='btl',
                                host=os.environ['BTL_DB_HOST'],
                                password=os.environ['BTL_DB_PASS'])
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)

        cursor = conn.cursor()

    data = {}
    ch_data = {}
    ct_thres = 2  # Number of std. devs.
    ct_data = {}
    if args.crosstalk:
        ct_ch = f'ch{args.crosstalk[0]}'
        ct_waveforms = {}
    with h5py.File(args.filename) as f:
        root_f = ROOT.TFile(args.output, "recreate")

        if args.upload:
            if 'sodium' not in dict(f):
                print("Missing sodium data!", file=sys.stderr)
                sys.exit(1)
            if 'spe' not in dict(f):
                print("Missing SPE data!", file=sys.stderr)
                sys.exit(1)
            for param in f['sodium'].attrs:
                if f['sodium'].attrs[param] != f['spe'].attrs[param]:
                    print(f"Conflict in {param} used to take sodium and SPE data!", file=sys.stderr)
                    sys.exit(1)
            if 'data_source' in f['sodium'].attrs:
                if f['sodium'].attrs['data_source'] != b'CAEN':
                    print("Error: trying to upload non-CAEN data!", file=sys.stderr)
                    sys.exit(1)
            else:
                print("Data source not specified!", file=sys.stderr)
                sys.exit(1)
            
            data['barcode'] = int(f['sodium'].attrs['barcode'])
            data['voltage'] = int(f['sodium'].attrs['voltage'])
            data['git_sha1'] = f['sodium'].attrs['git_sha1'].decode("UTF-8")
            data['git_dirty'] = f['sodium'].attrs['git_dirty'].decode("UTF-8")
            data['institution'] = str(args.institution)
            data['filename'] = args.filename

            cursor.execute("INSERT INTO runs (voltage, institution, git_sha1, git_dirty, filename) VALUES (%(voltage)s, %(institution)s::inst, %(git_sha1)s, %(git_dirty)s, %(filename)s) RETURNING run", data)
            result = cursor.fetchone()
            run = result[0]
        for group in f:
            if group != 'sodium' and group != 'spe':
                print(f"Unknown group name: \"{group}\". Skipping...")
                continue

            # All relevant channels from the scope and digitizer should be
            # in this format: 'ch<channel number>'.
            chs = [ch for ch in list(f[group]) if ch.startswith('ch')]
            
            chs = [ch for ch in chs if args.channel_mask // 2**int(ch[2:]) % 2]

            if args.crosstalk:
                if ct_ch not in chs:
                    print('Crosstalk channel not in file or not included in channel mask!', file=sys.stderr)
                    sys.exit(1)
                else:
                    chs.remove(ct_ch)
                    chs.insert(0, ct_ch)
            for channel in chs:
                if channel not in ch_data:
                    ch_data[channel] = {'channel': int(channel[2:])}
                
                if args.upload:
                    ch_data[channel]['run'] = run
                    ch_data[channel]['barcode'] = data['barcode']
                 
                charge = []
                f_charge = []
                
                ##################
                # Integrations
                ##################
                for i in range(0, len(f[group][channel]), args.chunks):
                    x, y = convert_data(f, group, channel, i, i+args.chunks)
                    if group == 'sodium':
                        a, b = get_window(x,y, left=50, right=300)
                        # Add SPE baseline subtraction method here?
                        y -= np.median(y[:,x < x[0] + 100],axis=-1)[:,np.newaxis]
                        if 'avg_pulse_y' in ch_data[channel]:
                            ch_data[channel]['avg_pulse_y'] = (ch_data[channel]['avg_pulse_count']*ch_data[channel]['avg_pulse_y'] + len(y)*np.mean(y, axis=0)) / (ch_data[channel]['avg_pulse_count'] + len(y))
                            ch_data[channel]['avg_pulse_count'] += len(y)
                            np.append(ch_data[channel]['sodium_rise_time'], get_rise_time(x, y))
                            np.append(ch_data[channel]['sodium_fall_time'], get_fall_time(x, y))
                        else:
                            ch_data[channel]['avg_pulse_y'] = np.mean(y, axis=0)
                            ch_data[channel]['avg_pulse_count'] = len(y)
                            ch_data[channel]['avg_pulse_x'] = x
                            ch_data[channel]['sodium_rise_time'] = get_rise_time(x, y)
                            ch_data[channel]['sodium_fall_time'] = get_fall_time(x, y)
                    elif group == 'spe':
                        a, b = get_spe_window(x, args.start_time, args.integration_time)
                        y, high_filter_y = spe_baseline_subtraction(x, y, method=args.integration_method)                        
                        f_charge.extend(integrate(x, high_filter_y, a, b))
                    
                    temp_charge = integrate(x,y,a,b)
                    
                    if args.crosstalk and group == 'sodium' and channel != ct_ch and ch_data[ct_ch]['sodium_peak'] is not None:
                        ct_ch_chg = np.array(ct_data[ct_ch][len(charge):len(charge)+len(temp_charge)])
                        ct_511_chg = ch_data[ct_ch]['sodium_peak'][0]
                        ct_511_std = ch_data[ct_ch]['sodium_peak'][2]
                        mask = ct_mask(ct_ch_chg, ct_511_chg, ct_511_std, ct_thres)
                        if channel not in ct_waveforms:
                            ct_waveforms[channel] = y[mask,:]
                        else:
                            ct_waveforms[channel] = np.append(ct_waveforms[channel], y[mask, :], axis=0)

                    charge.extend(temp_charge)
                
                if group == 'sodium':
                    ct_data[channel] = charge
                        
                if args.plot or args.print_pdfs:
                    if group == 'sodium':
                        avg_y = ch_data[channel]['avg_pulse_y']
                        plot_time_volt(x, y, f'{channel} {group}', a, b, avg_y=avg_y, pdf=args.print_pdfs, filename=args.filename)
                    else:
                        plot_time_volt(x, y, f'{channel} {group}', a, b, pdf=args.print_pdfs, filename=args.filename)
                    
                    if args.crosstalk and channel != ct_ch and group == 'sodium':
                        plot_time_volt(x, ct_waveforms[channel], f'Crosstalk in {channel} when Triggering on {ct_ch}', a, b, pdf=args.print_pdfs, filename=args.filename)
                    # Plotting the filtered voltage signal. Doesn't have to be included in the final draft of this code.
                    if group == 'spe':
                        plot_time_volt(x, high_filter_y, f"{channel} high filter {group}", a, b, pdf=args.print_pdfs, filename=args.filename)
                
                ##################
                # Creating Histogram
                ##################
                if group == 'sodium':
                    if np.max(charge) < 200:
                        print(f'Warning: Abnormally low sodium charge in {channel}. 511 charge will not be accurate.')
                        bins = get_bins(charge, cutoff=0)
                    else:
                        bins = get_bins(charge, cutoff=200)
                else:
                    bins = get_bins(charge)
                h = ROOT.TH1D(f"{group}_{channel}", f"{group} Charge Integral for {channel}", len(bins), bins[0], bins[-1])
                hists.append(h)
                for x in charge:
                    h.Fill(x)
                h.GetXaxis().SetTitle("Charge (pC)")
                h.Write()
                if group == 'spe':
                    f_bins = get_bins(f_charge)
                    f_h = ROOT.TH1D(f'f_{channel}', f"Filtered Charge {group} Integral for {channel}", len(f_bins), f_bins[0], f_bins[-1])
                    hists.append(f_h)
                    for x in f_charge:
                        f_h.Fill(x)
                    f_h.GetXaxis().SetTitle('Charge (pC)')
                    f_h.Write()
                
                ##################
                # Preparing Data for Upload
                ##################
                if args.upload:
                    bincenters = (bins[:1] + bins[:-1])/2
                    if group == 'sodium':
                        ch_data[channel]['sodium_rise_time'] = float(np.median(ch_data[channel]['sodium_rise_time']))
                        ch_data[channel]['sodium_fall_time'] = float(np.median(ch_data[channel]['sodium_rise_time']))
                        ch_data[channel]['avg_pulse_x'] = list(map(float,ch_data[channel]['avg_pulse_x']))
                        ch_data[channel]['avg_pulse_y'] = list(map(float,ch_data[channel]['avg_pulse_y']))
                        ch_data[channel]['sodium_charge_histogram_y'] = list(map(float,np.histogram(charge,bins=bins)[0]))
                        ch_data[channel]['sodium_charge_histogram_x'] = list(map(float,bincenters))
                    else:
                        ch_data[channel]['spe_charge_histogram_y'] = list(map(float,np.histogram(charge,bins=bins)[0]))
                        ch_data[channel]['spe_charge_histogram_x'] = list(map(float,bincenters))

                ##################
                # Fitting Histogram
                ##################
                print(f'Fitting {group} {channel}!')
                if group == 'spe':
                    model = fit_spe_funcs.vinogradov_model()
                    ch_data[channel]['spe'] = fit_spe_funcs.fit_spe(h, model, f_h=f_h)
                else:                    
                    thres = 400
                    ch_data[channel]['sodium_peak'] = fit_511_funcs.fit_511(h, charge_threshold=thres)
                if args.plot:
                    plot_hist(h, pdf=args.print_pdfs, filename=args.filename)

    ##################
    # Crosstalk Analysis
    ##################
    matrix = np.matrix(np.full((8,8), None)) # Row number is the trigger channel
    for dem_ch in ct_data:
        if args.crosstalk:
            if dem_ch != ct_ch:
                continue
        if ch_data[dem_ch]['sodium_peak'] is None:
            continue
        ct_511_chg = ch_data[dem_ch]['sodium_peak'][0]
        ct_511_std = ch_data[dem_ch]['sodium_peak'][2]
        dem_norm = np.array(ct_data[dem_ch]) / ct_511_chg

        mask = ct_mask(np.array(ct_data[dem_ch]), ct_511_chg, ct_511_std, ct_thres)

        plt.figure()
        plt.hist(np.array(ct_data[dem_ch])[mask], bins=get_bins(np.array(ct_data[dem_ch])[mask]), histtype='step')
        plt.suptitle(f'{dem_ch} Trigger Events for Crosstalk')
        
        plt.figure()
        for num_ch in ct_data:
            if num_ch == dem_ch:
                continue
            if ch_data[num_ch]['sodium_peak'] is None:
                continue

            num_norm = np.array(ct_data[num_ch]) / ch_data[num_ch]['sodium_peak'][0]
            
            charge_ratio = num_norm[mask]/dem_norm[mask]
            
            matrix[int(dem_ch[2:]), int(num_ch[2:])] = np.median(charge_ratio[charge_ratio <= np.percentile(charge_ratio, 95)])

            plt.hist(charge_ratio, bins=get_bins(charge_ratio), histtype='step', label=f'{num_ch}')
            plt.suptitle(f'Charge {num_ch}/Charge {dem_ch}')
            plt.xlim(left=-0.1, right=1)
        plt.legend()
        plt.suptitle(f'{dem_ch} Crosstalk Charge')
    print(matrix)
    
    ##################
    # Reviewing Data
    ##################
    for channel in ch_data:
        if 'sodium_peak' not in ch_data[channel]:
            print(f'Mising sodium data for {channel}!')
        elif 'spe' not in ch_data[channel]:
            print(f'Missing SPE data for {channel}!')
        elif ch_data[channel]['sodium_peak'] is None:
            print(f'Failed to fit {channel} sodium histogram!')
        elif ch_data[channel]['spe'] is None:
            print(f'Failed to fit {channel} spe histogram!')
        else:
            print(f'{channel}: {ch_data[channel]["sodium_peak"][0] / ch_data[channel]["spe"][0] / 0.511}')
            
            ##################
            # Uploading Data
            ##################
            if args.upload:
                # ch_data[channel]['sodium_peak'][0] is the charge value
                # ch_data[channel]['sodium_peak'][1] is the charge error
                ch_data[channel]['sodium_peak'] = ch_data[channel]['sodium_peak'][0] 
                ch_data[channel]['spe'] = ch_data[channel]['spe'][0] 
                ch_data[channel]['crosstalk'] = [float(val) if val is not None else None for val in matrix.A[int(channel[2:])]]
                result = cursor.execute("INSERT INTO data (channel, barcode, sodium_peak, spe, sodium_rise_time, sodium_fall_time, sodium_charge_histogram_x, sodium_charge_histogram_y, spe_charge_histogram_x, spe_charge_histogram_y, avg_pulse_x, avg_pulse_y, run, crosstalk) VALUES (%(channel)s, %(barcode)s, %(sodium_peak)s, %(spe)s, %(sodium_rise_time)s, %(sodium_fall_time)s, %(sodium_charge_histogram_x)s, %(sodium_charge_histogram_y)s, %(spe_charge_histogram_x)s, %(spe_charge_histogram_y)s, %(avg_pulse_x)s, %(avg_pulse_y)s, %(run)s, %(crosstalk)s)", ch_data[channel])
   

    root_f.Close()

    if args.plot:
        plt.show()

